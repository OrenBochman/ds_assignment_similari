OPTIMIZING MACHINE LEARNING RUNNING TIME
An optimization of running time for performing a machine learning algorithm on a processor architecture may be performed and include determining a plurality of parameters to be configured in the machine learning algorithm, and initiating, in the optimization, a plurality of iterations of performance of the machine learning algorithm by the processor architecture. Each of the iterations may include detecting a running time of an immediately preceding one of the iterations, changing a value of one of the parameters used in the immediately preceding iteration to form a new set of values, where the value is changed based on the detected running time of the immediately preceding iteration and according to a downhill simplex algorithm. An optimal set of values for the parameters may be determined based on the plurality of iterations to realize a minimum running time to complete performance of the machine learning algorithm by the processor architecture.